{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### How to AnomalyMatch\n",
                "\n",
                "#### 1. Recommended Folder Structure\n",
                "\n",
                "- project/\n",
                "  - labeled_data.csv | containing annotations of labeled examples\n",
                "  - training_images/ | the cfg.data_dir\n",
                "    - image1.jpeg\n",
                "    - image2.jpeg\n",
                "  - data_to_predict/ | the cfg.search_dir\n",
                "    - unlabeled_file_part1.hdf5\n",
                "    - unlabeled_file_part2.hdf5\n",
                "\n",
                "Example of a minimal labeled_data.csv:\n",
                "\n",
                "```\n",
                "filename,label,your_custom_source_id\n",
                "image1.jpeg,normal,123456\n",
                "image2.jpeg,anomaly,424242\n",
                "```\n",
                "\n",
                "#### 2. Specify paths and configuration parameters below.\n",
                "\n",
                "#### 3. Refer to the \"UI Explanation\" section at the bottom for details on how to use the interface.\n",
                "\n",
                "#### 4. Datalabs-specific hints\n",
                "\n",
                "If you are using Datalabs, you can install additional modules with conda / mamba in the terminal via e.g. `conda install scipy`\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "import anomaly_match as am"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# We use a cfg DotMap (a dictionary with dot accessors) to store the configuration for the run\n",
                "cfg = am.get_default_cfg()\n",
                "cfg.name = \"my_test_run\"\n",
                "cfg.model_path = \"anomaly_match_results/saved_models/my_model.pth\"\n",
                "\n",
                "# Set the data directory\n",
                "# This directory should contain the images to be used for active labeling and training and testing\n",
                "cfg.data_dir = \"/media/home/AnomalyMatch/tests/test_data/\"\n",
                "\n",
                "# Set the label file\n",
                "cfg.label_file = \"/media/home/AnomalyMatch/tests/test_data/labeled_data.csv\"  # CSV mapping annotated images to labels\n",
                "\n",
                "# Set the search directory\n",
                "# You can predict on a large unlabeled dataset (*.hdf5,*.zip ideally) by setting this to the directory containing the unlabeled images / files\n",
                "# This will be triggered when you press evaluate_search_dir\n",
                "cfg.search_dir = \"<your_path>\"\n",
                "\n",
                "# Set the test ratio\n",
                "cfg.test_ratio = 0.0  # Proportion of data used for evaluation (0.0 disables test evaluation, > 0 shows AUROC/AUPRC curves)\n",
                "\n",
                "# Set the number of unlabeled images to load\n",
                "cfg.N_to_load = 100  # Number of unlabeled images loaded into the training dataset at once\n",
                "\n",
                "# Set the image size\n",
                "cfg.size = [64, 64]  # Dimensions to which images are resized (below 96x96 is not recommended)\n",
                "\n",
                "# Set the logger level (options: \"trace\",\"debug\", \"info\", \"warning\", \"error\", \"critical\")\n",
                "logger_level = \"info\"\n",
                "am.set_log_level(logger_level, cfg)\n",
                "\n",
                "# Create a session\n",
                "session = am.Session(cfg)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Start the UI\n",
                "session.start_UI()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### UI Explanation\n",
                "\n",
                "The UI consists of several components:\n",
                "\n",
                "1. **Image Display Area**: This area shows the currently selected image along with its score and label. The image can be manipulated using the controls below it.\n",
                "\n",
                "2. **Control Buttons**:\n",
                "\n",
                "   - **Save Model**: Saves the current model state to disk.\n",
                "   - **Load Model**: Loads a previously saved model from model path.\n",
                "   - **Save Labels**: Saves the current labels to disk (will not overwrite the original labels file).\n",
                "   - **Load Top Files**: Loads the top anomalies from a search run.\n",
                "   - **Remember**: Adds the current image to the remembered list for follow-up.\n",
                "\n",
                "3. **Image Manipulation Controls**:\n",
                "\n",
                "   - **Invert Image**: Inverts the colors of the image.\n",
                "   - **Restore**: Restores the image to its original state.\n",
                "   - **Apply Unsharp Mask**: Applies an unsharp mask to the image to enhance edges.\n",
                "   - **Brightness and Contrast Sliders**: Adjust the brightness and contrast of the image.\n",
                "\n",
                "4. **Navigation Buttons**:\n",
                "\n",
                "   - **Previous**: Moves to the previous image.\n",
                "   - **Anomalous**: Marks the image as anomalous for next trainings (Original label_file will not be overwritten).\n",
                "   - **Nominal**: Marks the image as nominal for next trainings (Original label_file will not be overwritten).\n",
                "   - **Next**: Moves to the next image.\n",
                "\n",
                "5. **Training Controls**:\n",
                "\n",
                "   - **Train Iterations**: Sets the number of training iterations.\n",
                "   - **Batch Size**: Sets the amount of unlabeled images to be used in each training batch (watch out for memory constraints).\n",
                "   - **Train**: Starts the training process.\n",
                "   - **Evaluate Search Dir**: Evaluates the images in the search directory.\n",
                "\n",
                "6. **Model Controls**:\n",
                "\n",
                "   - **Reset Model**: Resets the model to its initial state.\n",
                "   - **Next Batch**: Loads the next batch unlabeled batch of images for prediction.\n",
                "\n",
                "7. **Top Images Display**: Shows the top 4 anomalous and top 4 nominal images based on the scores.\n",
                "\n",
                "This UI allows users to interactively label images, adjust image properties, and manage the training and evaluation process.\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "am",
            "language": "python",
            "name": "am"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
